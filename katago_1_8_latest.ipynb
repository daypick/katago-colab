{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "katago-1.8-latest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daypick/katago-colab/blob/master/katago_1_8_latest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB-AzfYAv0uY",
        "outputId": "4088fec5-8f6f-4706-a590-7ff895bec048"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May 16 07:14:18 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc701xWwO1DC"
      },
      "source": [
        "This document shows how to run KataGo on Colab, and how to connect it using `Sabaki`, `Lizzie` (or other GTP engine supported apps) in your local machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPHRkIZXFsL2",
        "outputId": "e2635ff0-940b-428a-9de3-023ef1ea1b19"
      },
      "source": [
        "NGROK_TOKEN=\"1ra0YWxwAEUSKnPLTsOnCL0vBhr_6F97AL6M5hL5Mgxuk97VA\"\n",
        "USER_NAME=\"root\"\n",
        "USER_PASSWORD=\"latest\"\n",
        "\n",
        "# optional args\n",
        "# supports: OPENCL, CUDA or AUTO\n",
        "KATAGO_BACKEND=\"CUDA\"\n",
        "# supports: 40b, 20b or AUTO\n",
        "WEIGHT_FILE=\"40b\" \n",
        "\n",
        "import subprocess\n",
        "gpu_name=str(subprocess.check_output(\"nvidia-smi -q | grep \\\"Product Name\\\" | cut -d\\\":\\\" -f2 | tr -cd '[:alnum:]._-'\", shell=True), encoding='utf-8')\n",
        "if KATAGO_BACKEND == \"AUTO\":\n",
        "  if gpu_name == \"TeslaT4\":\n",
        "    KATAGO_BACKEND=\"CUDA\"\n",
        "  else:\n",
        "    KATAGO_BACKEND=\"OPENCL\"\n",
        "\n",
        "if WEIGHT_FILE == \"AUTO\":\n",
        "  if gpu_name == \"TeslaK80\" or gpu_name == \"TeslaP4\":\n",
        "    WEIGHT_FILE=\"20b\"\n",
        "  else:\n",
        "    WEIGHT_FILE=\"40b\"\n",
        "\n",
        "!echo \"Using Katago Backend : \" $KATAGO_BACKEND\n",
        "!echo \"Using Katago Weight : \" $WEIGHT_FILE\n",
        "!echo \"GPU : \" $gpu_name\n",
        "\n",
        "# Install useful stuff\n",
        "!apt-get update 1>/dev/null\n",
        "!apt install --yes ssh screen nano htop ranger git libzip4 1>/dev/null\n",
        "!pip install oss2 1>/dev/null\n",
        "!wget -q https://github.com/wonsiks/katago-colab/releases/download/v1.8.0/libzip.so.5.0 -O /usr/lib/x86_64-linux-gnu/libzip.so.5\n",
        "%cd /content\n",
        "\n",
        "!rm -rf katago-colab\n",
        "!git clone https://github.com/kinfkong/katago-colab.git 1>/dev/null\n",
        "\n",
        "#download the binarires\n",
        "!wget -q https://github.com/wonsiks/katago-colab/releases/download/v1.8.2/katago-$KATAGO_BACKEND -O katago\n",
        "!chmod +x /content/katago\n",
        "!wget -q https://github.com/kinfkong/katago-colab/releases/download/v1.4.5/ngrok -O ngrok\n",
        "!chmod +x /content/ngrok\n",
        "!mkdir -p /root/.katago/\n",
        "!cp -r /content/katago-colab/opencltuning /root/.katago/\n",
        "\n",
        "\n",
        "################################################################################################\n",
        "#############download the weights #######################\n",
        "#weight_urls = {\n",
        "#    '40b': 'https://media.katagotraining.org/uploaded/networks/models/kata1/kata1-b40c256-s8003455744-d1941206379.bin.gz',\n",
        "#    '40n': 'https://media.katagotraining.org/uploaded/networks/models/kata1/kata1-b40c256-s8049900800-d1952632576.bin.gz'\n",
        "#}\n",
        "\n",
        "#weight_url = weight_urls[WEIGHT_FILE]\n",
        "#!wget --quiet $weight_url -O $WEIGHT_FILE\".bin.gz\" \n",
        "#!chmod +x $WEIGHT_FILE\".bin.gz\"\n",
        "#!rm -rf weight.bin.gz\n",
        "#!ln -s $WEIGHT_FILE\".bin.gz\" weight.bin.gz\n",
        "\n",
        "################################################################################################\n",
        "#download the weights\n",
        "#previous strongest:=> https://media.katagotraining.org/uploaded/networks/models/kata1/kata1-b40c256-s8096761856-d1963946463.bin.gz\n",
        "#srong=>  https://media.katagotraining.org/uploaded/networks/models/kata1/kata1-b40c256-s8003455744-d1941206379.bin.gz\n",
        "#latest=> https://media.katagotraining.org/uploaded/networks/models/kata1/kata1-b40c256-s8049900800-d1952632576.bin.gz\n",
        "#most-strong=> https://media.katagotraining.org/uploaded/networks/models/kata1/kata1-b40c256-s8003455744-d1941206379.bin.gz\n",
        "#second-strong https://media.katagotraining.org/uploaded/networks/models/kata1/kata1-b40c256-s8026817280-d1946950232.bin.gz\n",
        "\n",
        "!rm -rf weight.bin.gz\n",
        "\n",
        "if WEIGHT_FILE == \"40b\" :\n",
        "  !wget -q https://media.katagotraining.org/uploaded/networks/models/kata1/kata1-b40c256-s8073397504-d1958161418.bin.gz -O weight.bin.gz\n",
        "#  KATAGO_URL=open(\"kataurl.txt\", mode='r').read()\n",
        "#  !wget -q $KATAGO_URL -O weight.bin.gz\n",
        "else:\n",
        "  !wget -q https://media.katagotraining.org/uploaded/networks/models/kata1/kata1-b40c256-s8049900800-d1952632576.bin.gz -O weight.bin.gz\n",
        "\n",
        "# SSH setting\n",
        "!echo \"root:$USER_PASSWORD\" | chpasswd\n",
        "!echo \"PasswordAuthentication yes\" > /etc/ssh/sshd_config\n",
        "!echo \"PermitUserEnvironment yes\" >> /etc/ssh/sshd_config\n",
        "!echo \"PermitRootLogin yes\" >> /etc/ssh/sshd_config\n",
        "\n",
        "!mkdir -p /root/.ssh\n",
        "\n",
        "# generate the keys\n",
        "#!ssh-keygen -q -t rsa -N '' -f /root/.ssh/id_rsa <<<y 2>&1 >/dev/null\n",
        "#!cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys\n",
        "\n",
        "!service ssh restart > /dev/null\n",
        "\n",
        "# Run ngrok\n",
        "get_ipython().system_raw('./ngrok authtoken $NGROK_TOKEN && ./ngrok tcp 22 &')\n",
        "!sleep 5\n",
        "\n",
        "import oss2\n",
        "import requests\n",
        "import json\n",
        "from re import sub\n",
        "r = requests.get('http://localhost:4040/api/tunnels')\n",
        "raw_ssh = r.json()['tunnels'][0]['public_url']\n",
        "ssh_args = (sub(\"tcp://\", \"\", raw_ssh)).split(':')\n",
        "ssh_option = {\n",
        "    'host': ssh_args[0],\n",
        "    'port': int(ssh_args[1]),\n",
        "    'user': 'root'\n",
        "}\n",
        "\n",
        "ssh_option_json = json.dumps(ssh_option)\n",
        "\n",
        "endpoint = 'http://oss-cn-beijing.aliyuncs.com'\n",
        "auth = oss2.Auth('LTAI4G3tthX2R3Z8KY6Bdbs3', 'Q22UstMdKX8zZY9BqkGWWd2XbEBvPH')\n",
        "bucket = oss2.Bucket(auth, endpoint, 'kata-config')\n",
        "\n",
        "key = USER_NAME + '.ssh.json'\n",
        "bucket.put_object(key, ssh_option_json)\n",
        "\n",
        "if KATAGO_BACKEND == \"CUDA\":\n",
        "  %cd /usr/lib/x86_64-linux-gnu/\n",
        "  !wget -q https://github.com/wonsiks/katago-colab/releases/download/v1.8.0/libcublas.so.11.3.0.106 -O libcublas.so.11\n",
        "  !wget -q https://github.com/wonsiks/katago-colab/releases/download/v1.8.0/libcublasLt.so.11.3.0.106 -O libcublasLt.so.11\n",
        "  %cd /content\n",
        "  !wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/libcudnn8_8.0.5.39-1+cuda11.1_amd64.deb\n",
        "  !dpkg --configure -a\n",
        "  !dpkg -i libcudnn8_8.0.5.39-1+cuda11.1_amd64.deb\n",
        "else:\n",
        "  !wget -q https://raw.githubusercontent.com/wonsiks/katago-colab/master/opencltuning/tune8_gpuTeslaT4_x19_y19_c256_mv10.txt -O /root/.katago/opencltuning/tune8_gpuTeslaT4_x19_y19_c256_mv10.txt\n",
        "  !wget -q https://raw.githubusercontent.com/wonsiks/katago-colab/master/opencltuning/tune8_gpuTeslaT4_x19_y19_c256_mv8.txt -O /root/.katago/opencltuning/tune8_gpuTeslaT4_x19_y19_c256_mv8.txt\n",
        "  !wget -q https://raw.githubusercontent.com/wonsiks/katago-colab/master/opencltuning/tune8_gpuTeslaP4_x19_y19_c256_mv10.txt -O /root/.katago/opencltuning/tune8_gpuTeslaP4_x19_y19_c256_mv10.txt\n",
        "  !wget -q https://raw.githubusercontent.com/wonsiks/katago-colab/master/opencltuning/tune8_gpuTeslaK80_x19_y19_c256_mv10.txt -O /root/.katago/opencltuning/tune8_gpuTeslaK80_x19_y19_c256_mv10.txt\n",
        "  !wget -q https://raw.githubusercontent.com/wonsiks/katago-colab/master/opencltuning/tune8_gpuTeslaK80_x19_y19_c256_mv8.txt -O /root/.katago/opencltuning/tune8_gpuTeslaK80_x19_y19_c256_mv8.txt\n",
        "  !wget -q https://raw.githubusercontent.com/wonsiks/katago-colab/master/opencltuning/tune8_gpuTeslaP100PCIE16GB_x19_y19_c256_mv10.txt -O /root/.katago/opencltuning/tune8_gpuTeslaP100PCIE16GB_x19_y19_c256_mv10.txt\n",
        "  !wget -q https://raw.githubusercontent.com/wonsiks/katago-colab/master/opencltuning/tune8_gpuTeslaP100PCIE16GB_x19_y19_c256_mv8.txt -O /root/.katago/opencltuning/tune8_gpuTeslaP100PCIE16GB_x19_y19_c256_mv8.txt\n",
        "!wget https://github.com/wonsiks/katago-colab/releases/download/v1.8.0/gtp_colab.cfg\n",
        "!rm -rf /content/gtp_colab.cfg* && /content/kataurl.txt*\n",
        "!wget -q  -O /content/katago-colab/config/gtp_colab.cfg\n",
        "\n",
        "!echo -e \"\\n[KataGo Config]\" \n",
        "!cat /content/katago-colab/config/gtp_colab.cfg\n",
        "!echo -e \"\\n\"\n",
        "\n",
        "!echo \"Done! Now you can connect...\"\n",
        "!echo \"Engine command for Lizzie : ./colab-katago.exe \"$USER_NAME $USER_PASSWORD\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Katago Backend :  CUDA\n",
            "Using Katago Weight :  40b\n",
            "GPU :  TeslaV100-SXM2-16GB\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n",
            "/content\n",
            "Cloning into 'katago-colab'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Total 102 (delta 0), reused 0 (delta 0), pack-reused 102\u001b[K\n",
            "Receiving objects: 100% (102/102), 32.42 KiB | 4.63 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n",
            "ngrok: Text file busy\n",
            "/usr/lib/x86_64-linux-gnu\n",
            "/content\n",
            "--2021-05-16 07:14:49--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/libcudnn8_8.0.5.39-1+cuda11.1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.199.20.126\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.199.20.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 506495158 (483M) [application/x-deb]\n",
            "Saving to: ‘libcudnn8_8.0.5.39-1+cuda11.1_amd64.deb.6’\n",
            "\n",
            "libcudnn8_8.0.5.39- 100%[===================>] 483.03M   301MB/s    in 1.6s    \n",
            "\n",
            "2021-05-16 07:14:51 (301 MB/s) - ‘libcudnn8_8.0.5.39-1+cuda11.1_amd64.deb.6’ saved [506495158/506495158]\n",
            "\n",
            "(Reading database ... 164267 files and directories currently installed.)\n",
            "Preparing to unpack libcudnn8_8.0.5.39-1+cuda11.1_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.0.5.39-1+cuda11.1) over (8.0.5.39-1+cuda11.1) ...\n",
            "Setting up libcudnn8 (8.0.5.39-1+cuda11.1) ...\n",
            "--2021-05-16 07:15:38--  https://github.com/wonsiks/katago-colab/releases/download/v1.8.0/gtp_colab.cfg\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/310764858/f184cf80-767b-11eb-9a42-917d0b484254?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210516%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210516T071538Z&X-Amz-Expires=300&X-Amz-Signature=14e0fec2348f3dc335cd23bb8ce1c4b7b2cef3ada6cca83c3491d6a0f766cedc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=310764858&response-content-disposition=attachment%3B%20filename%3Dgtp_colab.cfg&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-05-16 07:15:38--  https://github-releases.githubusercontent.com/310764858/f184cf80-767b-11eb-9a42-917d0b484254?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210516%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210516T071538Z&X-Amz-Expires=300&X-Amz-Signature=14e0fec2348f3dc335cd23bb8ce1c4b7b2cef3ada6cca83c3491d6a0f766cedc&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=310764858&response-content-disposition=attachment%3B%20filename%3Dgtp_colab.cfg&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 468 [application/octet-stream]\n",
            "Saving to: ‘gtp_colab.cfg’\n",
            "\n",
            "gtp_colab.cfg       100%[===================>]     468  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-16 07:15:38 (22.6 MB/s) - ‘gtp_colab.cfg’ saved [468/468]\n",
            "\n",
            "/bin/bash: /content/kataurl.txt*: No such file or directory\n",
            "wget: missing URL\n",
            "Usage: wget [OPTION]... [URL]...\n",
            "\n",
            "Try `wget --help' for more options.\n",
            "\n",
            "[KataGo Config]\n",
            "# Config for C++ (non-python) gtp bot\n",
            "\n",
            "# RUNNING ON AN ONLINE SERVER OR IN A REAL TOURNAMENT OR MATCH:\n",
            "# If you plan to do so, you may want to read through the \"Rules\" section\n",
            "# below carefully for proper handling of komi and handicap games and end-of-game cleanup\n",
            "# and various other details.\n",
            "\n",
            "# NOTES ABOUT PERFORMANCE AND MEMORY USAGE:\n",
            "# You will likely want to tune one or more the following:\n",
            "#\n",
            "# numSearchThreads:\n",
            "# The number of CPU threads to use. If your GPU is powerful, it can actually be much higher than\n",
            "# the number of cores on your processor because you will need many threads to feed large enough\n",
            "# batches to make good use of the GPU.\n",
            "#\n",
            "# The \"./katago benchmark\" command can help you tune this parameter, as well as to test out the effect\n",
            "# of changes to any of the other parameters below!\n",
            "#\n",
            "# nnCacheSizePowerOfTwo:\n",
            "# This controls the NN Cache size, which is the primary RAM/memory use.\n",
            "# Increase this if you don't mind the memory use and want better performance for searches with\n",
            "# tens of thousands of visits or more. Decrease this if you want to limit memory usage.\n",
            "#\n",
            "# If you're someone who is happy to do a bit of math - each neural net entry takes very\n",
            "# approximately 1.5KB, except when using whole-board ownership/territory visualizations, each\n",
            "# entry will take very approximately 3KB. The number of entries is (2 ** nnCacheSizePowerOfTwo),\n",
            "# for example 2 ** 18 = 262144.\n",
            "#\n",
            "# OTHER NOTES:\n",
            "# If you have more than one GPU, take a look at \"OpenCL GPU settings\" or \"CUDA GPU settings\" below.\n",
            "#\n",
            "# If using OpenCL, you will want to verify that KataGo is picking up the correct device!\n",
            "# (e.g. some systems may have both an Intel CPU OpenCL and GPU OpenCL, if KataGo appears to pick\n",
            "# the wrong one, you correct this by specifying \"openclGpuToUse\" below).\n",
            "#\n",
            "# You may also want to adjust \"maxVisits\", \"ponderingEnabled\", \"resignThreshold\", and possibly\n",
            "# other parameters depending on your intended usage.\n",
            "#\n",
            "# ----------------------------------------------------------------------------------------\n",
            "\n",
            "# For the `katago gtp` command, ALL of THE BELOW VALUES MAY BE SET OR OVERRIDDEN if desired via\n",
            "# the command line arguments:\n",
            "# -override-config KEY=VALUE,KEY=VALUE,...\n",
            "\n",
            "# Logs and files--------------------------------------------------------------------------\n",
            "\n",
            "# Where to output log?\n",
            "logDir = gtp_logs    # Each run of KataGo will log to a separate file in this dir\n",
            "# logFile = gtp.log  # Use this instead of logDir to just specify a single file directly\n",
            "\n",
            "# Logging options\n",
            "logAllGTPCommunication = true\n",
            "logSearchInfo = true\n",
            "logToStderr = false\n",
            "\n",
            "# KataGo will display some info to stderr on GTP startup\n",
            "# Uncomment this to suppress that and remain silent\n",
            "# startupPrintMessageToStderr = false\n",
            "\n",
            "# Chat some stuff to stderr, for use in things like malkovich chat to OGS.\n",
            "# ogsChatToStderr = true\n",
            "\n",
            "# Optionally override where KataGo will attempt to save things like openCLTuner files and other cached data.\n",
            "# homeDataDir = DIRECTORY\n",
            "\n",
            "# Analysis------------------------------------------------------------------------------------\n",
            "\n",
            "# Configure the maximum length of analysis printed out by lz-analyze and other places.\n",
            "# Controls the number of moves after the first move in a variation.\n",
            "# analysisPVLen = 15\n",
            "\n",
            "# Report winrates for chat and analysis as (BLACK|WHITE|SIDETOMOVE).\n",
            "# Default is SIDETOMOVE, which is what tools that use LZ probably also expect\n",
            "# reportAnalysisWinratesAs = SIDETOMOVE\n",
            "\n",
            "# Uncomment and and set to a positive value to make KataGo explore the top move(s) less deeply and accurately,\n",
            "# but explore and give evaluations to a greater variety of moves, for analysis (does NOT affect play).\n",
            "# A value like 0.03 or 0.06 will give various mildly but still noticeably wider searches.\n",
            "# An extreme value like 1 will distribute many playouts across every move on the board, even very bad moves.\n",
            "# analysisWideRootNoise = 0.0\n",
            "\n",
            "\n",
            "# Default rules------------------------------------------------------------------------------------\n",
            "# See https://lightvector.github.io/KataGo/rules.html for a description of the rules.\n",
            "# These rules are defaults and can be changed mid-run by several custom GTP commands.\n",
            "# See https://github.com/lightvector/KataGo/blob/master/docs/GTP_Extensions.md for those commands.\n",
            "\n",
            "# Some other legal values are: \"chinese\", \"japanese\", \"korean\", \"aga\", \"chinese-ogs\", \"new-zealand\".\n",
            "# KataGo does not claim to exactly match any particular human ruleset, but KataGo will try to behave\n",
            "# as closely as possible given the rules it has implemented.\n",
            "rules = tromp-taylor\n",
            "\n",
            "# Use the below instead to specify an arbitrary combination of individual rules.\n",
            "\n",
            "# koRule = SIMPLE       # Simple ko rules (triple ko = no result)\n",
            "# koRule = POSITIONAL   # Positional superko\n",
            "# koRule = SITUATIONAL  # Situational superko\n",
            "\n",
            "# scoringRule = AREA       # Area scoring\n",
            "# scoringRule = TERRITORY  # Territory scoring (uses a sort of special computer-friendly territory ruleset)\n",
            "\n",
            "# taxRule = NONE  # All surrounded empty points are scored\n",
            "# taxRule = SEKI  # Eyes in seki do NOT count as points\n",
            "# taxRule = ALL   # All groups are taxed up to 2 points for the two eyes needed to live\n",
            "\n",
            "# multiStoneSuicideLegal = true  #Is multiple-stone suicide legal? (Single-stone suicide is always illegal).\n",
            "\n",
            "# hasButton = false # Set to true when area scoring to award 0.5 points to the first pass.\n",
            "\n",
            "# whiteHandicapBonus = 0    # In handicap games, give white no compensation for black's handicap stones (Tromp-taylor, NZ, JP)\n",
            "# whiteHandicapBonus = N-1  # In handicap games, give white N-1 points for black's handicap stones (AGA)\n",
            "# whiteHandicapBonus = N    # In handicap games, give white N points for black's handicap stones (Chinese)\n",
            "\n",
            "# Uncomment and change to adjust what board size KataGo uses upon startup by default if GTP doesn't specify.\n",
            "# defaultBoardSize = 19\n",
            "\n",
            "# Bot behavior---------------------------------------------------------------------------------------\n",
            "\n",
            "# Resignation -------------\n",
            "\n",
            "# Resignation occurs if for at least resignConsecTurns in a row,\n",
            "# the winLossUtility (which is on a [-1,1] scale) is below resignThreshold.\n",
            "allowResignation = true\n",
            "resignThreshold = -0.90\n",
            "resignConsecTurns = 3\n",
            "# Uncomment to make katago not resign close games, behind by fewer than this many points\n",
            "# resignMinScoreDifference = 10\n",
            "\n",
            "# Handicap -------------\n",
            "\n",
            "# Assume that if black makes many moves in a row right at the start of the game, then the game is a handicap game.\n",
            "# This is necessary on some servers and for some GUIs and also when initializing from many SGF files, which may\n",
            "# set up a handicap game using repeated GTP \"play\" commands for black rather than GTP \"place_free_handicap\" commands.\n",
            "# However, it may also lead to incorrect understanding of komi if whiteHandicapBonus is used and a server does NOT\n",
            "# have such a practice.\n",
            "# Defaults to true! Uncomment and set to false to disable this behavior.\n",
            "# assumeMultipleStartingBlackMovesAreHandicap = true\n",
            "\n",
            "# Makes katago dynamically adjust in handicap or altered-komi games to assume based on those game settings that it\n",
            "# must be stronger or weaker than the opponent and to play accordingly. Greatly improves handicap\n",
            "# strength by biasing winrates and scores to favor appropriate safe/aggressive play.\n",
            "# Does NOT affect analysis (lz-analyze, kata-analyze, used by programs like Lizzie) so analysis remains unbiased.\n",
            "# Uncomment and set this to 0 to disable this and make KataGo play the same always.\n",
            "# dynamicPlayoutDoublingAdvantageCapPerOppLead = 0.045\n",
            "\n",
            "# Instead of a dynamic level, you can uncomment this and set this to a value from -3.0 to 3.0 to set KataGo's aggression to a FIXED level.\n",
            "# DOES affect analysis tools (lz-analyze, kata-analyze, used by programs like Lizzie).\n",
            "# Negative makes KataGo behave as if it is much weaker than the opponent, preferring to play defensively.\n",
            "# Positive makes KataGo behave as if it is much stronger than the opponent, prefering to play aggressively or even overplay slightly.\n",
            "# If this and \"dynamicPlayoutDoublingAdvantageCapPerOppLead\" are BOTH set then dynamic will be used for all games and this fixed\n",
            "# value will be used for analysis tools.\n",
            "# playoutDoublingAdvantage = 0.0\n",
            "\n",
            "# Uncommenting one of these will enforce that the FIXED playoutDoublingAdvantage will only apply when KataGo plays the specified color\n",
            "# and will be negated when playing the opposite color.\n",
            "# playoutDoublingAdvantagePla = BLACK\n",
            "# playoutDoublingAdvantagePla = WHITE\n",
            "\n",
            "# Passing and cleanup -------------\n",
            "\n",
            "# Make the bot never assume that its pass will end the game, even if passing would end and \"win\" under Tromp-Taylor rules.\n",
            "# Usually this is a good idea when using it for analysis or playing on servers where scoring may be implemented non-tromp-taylorly.\n",
            "# Defaults to true! Uncomment and set to false to disable this.\n",
            "# conservativePass = true\n",
            "\n",
            "# When using territory scoring, self-play games continue beyond two passes with special cleanup\n",
            "# rules that may be confusing for human players. This option prevents the special cleanup phases from being\n",
            "# reachable when using the bot for GTP play.\n",
            "# Defaults to true! Uncomment and set to false if you want KataGo to be able to enter special cleanup.\n",
            "# For example, if you are testing it against itself, or against another bot that has precisely implemented the rules\n",
            "# documented at https://lightvector.github.io/KataGo/rules.html\n",
            "# preventCleanupPhase = true\n",
            "\n",
            "# Misc Behavior --------------------\n",
            "\n",
            "# Uncomment and set to true to make KataGo avoid a particular joseki that some KataGo nets misevaluate,\n",
            "# and also to improve opening diversity versus some particular other bots that like to play it all the time.\n",
            "# avoidMYTDaggerHack = false\n",
            "\n",
            "# Search limits-----------------------------------------------------------------------------------\n",
            "\n",
            "# For all of \"maxVisits\", \"maxPlayouts\", \"maxTime\", search will still try to follow GTP time controls and may make a move\n",
            "# faster than the specified max if GTP tells it that it is playing under a clock as well in the current game.\n",
            "\n",
            "# If provided, limit maximum number of root visits per search to this much. (With tree reuse, visits do count earlier search)\n",
            "maxVisits = 500\n",
            "# If provided, limit maximum number of new playouts per search to this much. (With tree reuse, playouts do not count earlier search)\n",
            "# maxPlayouts = 300\n",
            "# If provided, cap search time at this many seconds.\n",
            "# maxTime = 10\n",
            "\n",
            "# Ponder on the opponent's turn?\n",
            "ponderingEnabled = true\n",
            "maxTimePondering = 60  # Maximum time to ponder, in seconds. Comment out to make unlimited.\n",
            "# Note: you can set \"maxVisitsPondering\" or \"maxPlayoutsPondering\" too.\n",
            "\n",
            "# Number of seconds to buffer for lag for GTP time controls - will move a bit faster assuming there is this much lag per move.\n",
            "lagBuffer = 1.0\n",
            "\n",
            "# Number of threads to use in search\n",
            "numSearchThreads = 12\n",
            "\n",
            "# Play a little faster if the opponent is passing, for friendliness\n",
            "searchFactorAfterOnePass = 0.50\n",
            "searchFactorAfterTwoPass = 0.25\n",
            "# Play a little faster if super-winning, for friendliness\n",
            "searchFactorWhenWinning = 0.40\n",
            "searchFactorWhenWinningThreshold = 0.95\n",
            "\n",
            "# GPU Settings-------------------------------------------------------------------------------\n",
            "\n",
            "# Maximum number of positions to send to a single GPU at once.\n",
            "# The default value here is roughly equal to numSearchThreads, but you can specify it manually\n",
            "# if you are running out of memory, or if you are using multiple GPUs that expect to split\n",
            "# up the work.\n",
            "# nnMaxBatchSize = <integer>\n",
            "\n",
            "# Cache up to (2 ** this) many neural net evaluations in case of transpositions in the tree.\n",
            "# Uncomment and edit to change if you want to adjust a major component of KataGo's RAM usage.\n",
            "# nnCacheSizePowerOfTwo = 20\n",
            "\n",
            "# Size of mutex pool for nnCache is (2 ** this).\n",
            "# nnMutexPoolSizePowerOfTwo = 16\n",
            "\n",
            "# Randomize board orientation when running neural net evals? Uncomment and set to false to disable.\n",
            "# nnRandomize = true\n",
            "# If provided, force usage of a specific seed for nnRandomize instead of randomizing.\n",
            "# nnRandSeed = abcdefg\n",
            "\n",
            "# TO USE MULTIPLE GPUS:\n",
            "# Set this to the number of GPUs you have and/or would like to use.\n",
            "# **AND** if it is more than 1, uncomment the appropriate CUDA or OpenCL section below.\n",
            "# numNNServerThreadsPerModel = 1\n",
            "\n",
            "# CUDA GPU settings--------------------------------------\n",
            "# These only apply when using the CUDA version of KataGo.\n",
            "\n",
            "# IF USING ONE GPU: optionally uncomment and change this if the GPU you want to use turns out to be not device 0\n",
            "# cudaDeviceToUse = 0\n",
            "\n",
            "# IF USING TWO GPUS: Uncomment these two lines (AND set numNNServerThreadsPerModel above):\n",
            "# cudaDeviceToUseThread0 = 0  # change this if the first GPU you want to use turns out to be not device 0\n",
            "# cudaDeviceToUseThread1 = 1  # change this if the second GPU you want to use turns out to be not device 1\n",
            "\n",
            "# IF USING THREE GPUS: Uncomment these three lines (AND set numNNServerThreadsPerModel above):\n",
            "# cudaDeviceToUseThread0 = 0  # change this if the first GPU you want to use turns out to be not device 0\n",
            "# cudaDeviceToUseThread1 = 1  # change this if the second GPU you want to use turns out to be not device 1\n",
            "# cudaDeviceToUseThread2 = 2  # change this if the third GPU you want to use turns out to be not device 2\n",
            "\n",
            "# You can probably guess the pattern if you have four, five, etc. GPUs.\n",
            "\n",
            "# KataGo will automatically use FP16 or not based on the compute capability of your NVIDIA GPU. If you\n",
            "# want to try to force a particular behavior though you can uncomment these lines and change them\n",
            "# to \"true\" or \"false\". E.g. it's using FP16 but on your card that's giving an error, or it's not using\n",
            "# FP16 but you think it should.\n",
            "# cudaUseFP16 = auto\n",
            "# cudaUseNHWC = auto\n",
            "\n",
            "\n",
            "# OpenCL GPU settings--------------------------------------\n",
            "# These only apply when using the OpenCL version of KataGo.\n",
            "\n",
            "# Uncomment to tune OpenCL for every board size separately, rather than only the largest possible size\n",
            "# openclReTunePerBoardSize = true\n",
            "\n",
            "# IF USING ONE GPU: optionally uncomment and change this if the best device to use is guessed incorrectly.\n",
            "# The default behavior tries to guess the 'best' GPU or device on your system to use, usually it will be a good guess.\n",
            "# openclDeviceToUse = 0\n",
            "\n",
            "# IF USING TWO GPUS: Uncomment these two lines and replace X and Y with the device ids of the devices you want to use.\n",
            "# It might NOT be 0 and 1, some computers will have many OpenCL devices. You can see what the devices are when\n",
            "# KataGo starts up - it should print or log all the devices it finds.\n",
            "# (AND also set numNNServerThreadsPerModel above)\n",
            "# openclDeviceToUseThread0 = X\n",
            "# openclDeviceToUseThread1 = Y\n",
            "\n",
            "# IF USING THREE GPUS: Uncomment these three lines and replace X and Y and Z with the device ids of the devices you want to use.\n",
            "# It might NOT be 0 and 1 and 2, some computers will have many OpenCL devices. You can see what the devices are when\n",
            "# KataGo starts up - it should print or log all the devices it finds.\n",
            "# (AND also set numNNServerThreadsPerModel above)\n",
            "# openclDeviceToUseThread0 = X\n",
            "# openclDeviceToUseThread1 = Y\n",
            "# openclDeviceToUseThread2 = Z\n",
            "\n",
            "# You can probably guess the pattern if you have four, five, etc. GPUs.\n",
            "\n",
            "\n",
            "# Root move selection and biases------------------------------------------------------------------------------\n",
            "# Uncomment and edit any of the below values to change them from their default.\n",
            "\n",
            "# If provided, force usage of a specific seed for various things in the search instead of randomizing\n",
            "# searchRandSeed = hijklmn\n",
            "\n",
            "# Temperature for the early game, randomize between chosen moves with this temperature\n",
            "# chosenMoveTemperatureEarly = 0.5\n",
            "# Decay temperature for the early game by 0.5 every this many moves, scaled with board size.\n",
            "# chosenMoveTemperatureHalflife = 19\n",
            "# At the end of search after the early game, randomize between chosen moves with this temperature\n",
            "# chosenMoveTemperature = 0.10\n",
            "# Subtract this many visits from each move prior to applying chosenMoveTemperature\n",
            "# (unless all moves have too few visits) to downweight unlikely moves\n",
            "# chosenMoveSubtract = 0\n",
            "# The same as chosenMoveSubtract but only prunes moves that fall below the threshold, does not affect moves above\n",
            "# chosenMovePrune = 1\n",
            "\n",
            "# Number of symmetries to sample (WITH replacement) and average at the root\n",
            "# rootNumSymmetriesToSample = 1\n",
            "\n",
            "# Using LCB for move selection?\n",
            "# useLcbForSelection = true\n",
            "# How many stdevs a move needs to be better than another for LCB selection\n",
            "# lcbStdevs = 5.0\n",
            "# Only use LCB override when a move has this proportion of visits as the top move\n",
            "# minVisitPropForLCB = 0.15\n",
            "\n",
            "# Internal params------------------------------------------------------------------------------\n",
            "# Uncomment and edit any of the below values to change them from their default.\n",
            "\n",
            "# Scales the utility of winning/losing\n",
            "# winLossUtilityFactor = 1.0\n",
            "# Scales the utility for trying to maximize score\n",
            "# staticScoreUtilityFactor = 0.10\n",
            "# dynamicScoreUtilityFactor = 0.30\n",
            "# Adjust dynamic score center this proportion of the way towards zero, capped at a reasonable amount.\n",
            "# dynamicScoreCenterZeroWeight = 0.20\n",
            "# dynamicScoreCenterScale = 0.75\n",
            "# The utility of getting a \"no result\" due to triple ko or other long cycle in non-superko rulesets (-1 to 1)\n",
            "# noResultUtilityForWhite = 0.0\n",
            "# The number of wins that a draw counts as, for white. (0 to 1)\n",
            "# drawEquivalentWinsForWhite = 0.5\n",
            "\n",
            "# Exploration constant for mcts\n",
            "# cpuctExploration = 0.9\n",
            "# cpuctExplorationLog = 0.4\n",
            "# FPU reduction constant for mcts\n",
            "# fpuReductionMax = 0.2\n",
            "# rootFpuReductionMax = 0.1\n",
            "# Use parent average value for fpu base point instead of point value net estimate\n",
            "# fpuUseParentAverage = true\n",
            "# Amount to apply a downweighting of children with very bad values relative to good ones\n",
            "# valueWeightExponent = 0.5\n",
            "# Slight incentive for the bot to behave human-like with regard to passing at the end, filling the dame,\n",
            "# not wasting time playing in its own territory, etc, and not play moves that are equivalent in terms of\n",
            "# points but a bit more unfriendly to humans.\n",
            "# rootEndingBonusPoints = 0.5\n",
            "# Make the bot prune useless moves that are just prolonging the game to avoid losing yet\n",
            "# rootPruneUselessMoves = true\n",
            "\n",
            "# How big to make the mutex pool for search synchronization\n",
            "# mutexPoolSize = 16384\n",
            "# How many virtual losses to add when a thread descends through a node\n",
            "# numVirtualLossesPerThread = 1\n",
            "\n",
            "\n",
            "Done! Now you can connect...\n",
            "Engine command for Lizzie : ./colab-katago.exe root latest\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1Wx4EZbOkS7"
      },
      "source": [
        "#The following sections are for debugging only, you can ignore."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUrfBH3MPBz4"
      },
      "source": [
        "**Shows the Colab GPU Info**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnh18L-MPE-n"
      },
      "source": [
        "Get your ssh login info\n",
        "*ssh login account is root, the login password is the `USER_PASSWORD` you configured in the previous steps*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogpJ83VzPHn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a27d22-bf44-4bb9-8fe8-e09552e8c107"
      },
      "source": [
        "import requests\n",
        "from re import sub\n",
        "r = requests.get('http://localhost:4040/api/tunnels')\n",
        "str_ssh = r.json()['tunnels'][0]['public_url']\n",
        "str_ssh = sub(\"tcp://\", \"\", str_ssh)\n",
        "str_ssh = sub(\":\", \" -p \", str_ssh)\n",
        "str_ssh = \"ssh root@\" + str_ssh \n",
        "print(str_ssh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ssh root@6.tcp.ngrok.io -p 15502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB2xmtRN9l78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec09699-240a-4c1d-95fe-e97cebaf938c"
      },
      "source": [
        "!./katago benchmark -model weight.bin.gz -config katago-colab/config/gtp_colab.cfg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-16 07:15:39+0000: Loading model and initializing benchmark...\n",
            "2021-05-16 07:15:39+0000: nnRandSeed0 = 17687316231351245371\n",
            "2021-05-16 07:15:39+0000: After dedups: nnModelFile0 = weight.bin.gz useFP16 auto useNHWC auto\n",
            "2021-05-16 07:15:41+0000: Cuda backend thread 0: Found GPU Tesla V100-SXM2-16GB memory 16945512448 compute capability major 7 minor 0\n",
            "2021-05-16 07:15:41+0000: Cuda backend thread 0: Model version 10 useFP16 = true useNHWC = true\n",
            "2021-05-16 07:15:41+0000: Cuda backend thread 0: Model name: kata1-b40c256-s8096761856-d1963946463\n",
            "\n",
            "2021-05-16 07:15:43+0000: Loaded config katago-colab/config/gtp_colab.cfg\n",
            "2021-05-16 07:15:43+0000: Loaded model weight.bin.gz\n",
            "\n",
            "Testing using 800 visits.\n",
            "  If you have a good GPU, you might increase this using \"-visits N\" to get more accurate results.\n",
            "  If you have a weak GPU and this is taking forever, you can decrease it instead to finish the benchmark faster.\n",
            "\n",
            "Your GTP config is currently set to cudaUseFP16 = auto and cudaUseNHWC = auto\n",
            "\n",
            "Your GTP config is currently set to use numSearchThreads = 12\n",
            "Automatically trying different numbers of threads to home in on the best: \n",
            "\n",
            "2021-05-16 07:15:43+0000: nnRandSeed0 = 15272498090485598458\n",
            "2021-05-16 07:15:43+0000: After dedups: nnModelFile0 = weight.bin.gz useFP16 auto useNHWC auto\n",
            "2021-05-16 07:15:45+0000: Cuda backend thread 0: Found GPU Tesla V100-SXM2-16GB memory 16945512448 compute capability major 7 minor 0\n",
            "2021-05-16 07:15:45+0000: Cuda backend thread 0: Model version 10 useFP16 = true useNHWC = true\n",
            "2021-05-16 07:15:45+0000: Cuda backend thread 0: Model name: kata1-b40c256-s8096761856-d1963946463\n",
            "\n",
            "\n",
            "Possible numbers of threads to test: 1, 2, 3, 4, 5, 6, 8, 10, 12, 16, 20, 24, 32, \n",
            "\n",
            "numSearchThreads =  5: 10 / 10 positions, visits/s = 746.92 nnEvals/s = 632.82 nnBatches/s = 254.21 avgBatchSize = 2.49 (10.8 secs)\n",
            "numSearchThreads = 12: 10 / 10 positions, visits/s = 1173.31 nnEvals/s = 992.32 nnBatches/s = 167.97 avgBatchSize = 5.91 (6.9 secs)\n",
            "numSearchThreads = 10: 10 / 10 positions, visits/s = 1102.07 nnEvals/s = 943.23 nnBatches/s = 191.67 avgBatchSize = 4.92 (7.3 secs)\n",
            "numSearchThreads = 20: 10 / 10 positions, visits/s = 1375.35 nnEvals/s = 1213.97 nnBatches/s = 124.10 avgBatchSize = 9.78 (6.0 secs)\n",
            "numSearchThreads = 16: 10 / 10 positions, visits/s = 1307.68 nnEvals/s = 1143.70 nnBatches/s = 146.01 avgBatchSize = 7.83 (6.2 secs)\n",
            "numSearchThreads = 24: 10 / 10 positions, visits/s = 1428.57 nnEvals/s = 1282.25 nnBatches/s = 110.22 avgBatchSize = 11.63 (5.8 secs)\n",
            "numSearchThreads = 32: 10 / 10 positions, visits/s = 1485.58 nnEvals/s = 1377.43 nnBatches/s = 90.64 avgBatchSize = 15.20 (5.6 secs)\n",
            "\n",
            "\n",
            "Optimal number of threads is fairly high, increasing the search limit and trying again.\n",
            "\n",
            "2021-05-16 07:16:36+0000: nnRandSeed0 = 1160831814273709729\n",
            "2021-05-16 07:16:36+0000: After dedups: nnModelFile0 = weight.bin.gz useFP16 auto useNHWC auto\n",
            "2021-05-16 07:16:37+0000: Cuda backend thread 0: Found GPU Tesla V100-SXM2-16GB memory 16945512448 compute capability major 7 minor 0\n",
            "2021-05-16 07:16:37+0000: Cuda backend thread 0: Model version 10 useFP16 = true useNHWC = true\n",
            "2021-05-16 07:16:37+0000: Cuda backend thread 0: Model name: kata1-b40c256-s8096761856-d1963946463\n",
            "\n",
            "\n",
            "Possible numbers of threads to test: 16, 20, 24, 32, 40, 48, 64, 80, 96, \n",
            "\n",
            "numSearchThreads = 64: 10 / 10 positions, visits/s = 1689.01 nnEvals/s = 1632.25 nnBatches/s = 55.39 avgBatchSize = 29.47 (5.1 secs)\n",
            "numSearchThreads = 40: 10 / 10 positions, visits/s = 1578.77 nnEvals/s = 1485.06 nnBatches/s = 78.47 avgBatchSize = 18.93 (5.3 secs)\n",
            "numSearchThreads = 80: 10 / 10 positions, visits/s = 1683.18 nnEvals/s = 1651.78 nnBatches/s = 45.77 avgBatchSize = 36.09 (5.2 secs)\n",
            "numSearchThreads = 48: 10 / 10 positions, visits/s = 1619.30 nnEvals/s = 1541.11 nnBatches/s = 68.25 avgBatchSize = 22.58 (5.2 secs)\n",
            "\n",
            "\n",
            "Ordered summary of results: \n",
            "\n",
            "numSearchThreads =  5: 10 / 10 positions, visits/s = 746.92 nnEvals/s = 632.82 nnBatches/s = 254.21 avgBatchSize = 2.49 (10.8 secs) (EloDiff baseline)\n",
            "numSearchThreads = 10: 10 / 10 positions, visits/s = 1102.07 nnEvals/s = 943.23 nnBatches/s = 191.67 avgBatchSize = 4.92 (7.3 secs) (EloDiff +133)\n",
            "numSearchThreads = 12: 10 / 10 positions, visits/s = 1173.31 nnEvals/s = 992.32 nnBatches/s = 167.97 avgBatchSize = 5.91 (6.9 secs) (EloDiff +152)\n",
            "numSearchThreads = 16: 10 / 10 positions, visits/s = 1307.68 nnEvals/s = 1143.70 nnBatches/s = 146.01 avgBatchSize = 7.83 (6.2 secs) (EloDiff +186)\n",
            "numSearchThreads = 20: 10 / 10 positions, visits/s = 1375.35 nnEvals/s = 1213.97 nnBatches/s = 124.10 avgBatchSize = 9.78 (6.0 secs) (EloDiff +198)\n",
            "numSearchThreads = 24: 10 / 10 positions, visits/s = 1428.57 nnEvals/s = 1282.25 nnBatches/s = 110.22 avgBatchSize = 11.63 (5.8 secs) (EloDiff +205)\n",
            "numSearchThreads = 32: 10 / 10 positions, visits/s = 1485.58 nnEvals/s = 1377.43 nnBatches/s = 90.64 avgBatchSize = 15.20 (5.6 secs) (EloDiff +207)\n",
            "numSearchThreads = 40: 10 / 10 positions, visits/s = 1578.77 nnEvals/s = 1485.06 nnBatches/s = 78.47 avgBatchSize = 18.93 (5.3 secs) (EloDiff +218)\n",
            "numSearchThreads = 48: 10 / 10 positions, visits/s = 1619.30 nnEvals/s = 1541.11 nnBatches/s = 68.25 avgBatchSize = 22.58 (5.2 secs) (EloDiff +215)\n",
            "numSearchThreads = 64: 10 / 10 positions, visits/s = 1689.01 nnEvals/s = 1632.25 nnBatches/s = 55.39 avgBatchSize = 29.47 (5.1 secs) (EloDiff +208)\n",
            "numSearchThreads = 80: 10 / 10 positions, visits/s = 1683.18 nnEvals/s = 1651.78 nnBatches/s = 45.77 avgBatchSize = 36.09 (5.2 secs) (EloDiff +181)\n",
            "\n",
            "\n",
            "Based on some test data, each speed doubling gains perhaps ~250 Elo by searching deeper.\n",
            "Based on some test data, each thread costs perhaps 7 Elo if using 800 visits, and 2 Elo if using 5000 visits (by making MCTS worse).\n",
            "So APPROXIMATELY based on this benchmark, if you intend to do a 5 second search: \n",
            "numSearchThreads =  5: (baseline)\n",
            "numSearchThreads = 10:  +133 Elo\n",
            "numSearchThreads = 12:  +152 Elo\n",
            "numSearchThreads = 16:  +186 Elo\n",
            "numSearchThreads = 20:  +198 Elo\n",
            "numSearchThreads = 24:  +205 Elo\n",
            "numSearchThreads = 32:  +207 Elo\n",
            "numSearchThreads = 40:  +218 Elo (recommended)\n",
            "numSearchThreads = 48:  +215 Elo\n",
            "numSearchThreads = 64:  +208 Elo\n",
            "numSearchThreads = 80:  +181 Elo\n",
            "\n",
            "If you care about performance, you may want to edit numSearchThreads in katago-colab/config/gtp_colab.cfg based on the above results!\n",
            "If you intend to do much longer searches, configure the seconds per game move you expect with the '-time' flag and benchmark again.\n",
            "If you intend to do short or fixed-visit searches, use lower numSearchThreads for better strength, high threads will weaken strength.\n",
            "If interested see also other notes about performance and mem usage in the top of katago-colab/config/gtp_colab.cfg\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX4yElWubmas",
        "outputId": "5b125763-4b22-488d-d8e9-167e82c901db"
      },
      "source": [
        "!./katago genconfig -model weight.bin.gz -output gtp_custom.cfg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File gtp_custom.cfg already exists, okay to overwrite it with an entirely new config (y/n)?\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uyu-DWX9lw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7abe370c-fc45-4fad-bef9-94f30b4b7648"
      },
      "source": [
        "!./katago version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KataGo v1.8.2\n",
            "Git revision: b846bddd88fbc5353e4a93fa514f6cbf45358362\n",
            "Compile Time: Apr 18 2021 16:55:08\n",
            "Using CUDA backend\n",
            "Compiled with CUDA version 11.1.105\n",
            "Compiled to support contributing to online distributed selfplay\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}